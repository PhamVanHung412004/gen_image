# import torch
# import numpy as np
# from transformers import CLIPProcessor, CLIPModel
# from PIL import Image
# import json
# from sklearn.metrics.pairwise import cosine_similarity

# class SwordSearchSystem:
#     def __init__(self):
#         # Load CLIP model
#         self.model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
#         self.processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
        
#         # Database l∆∞u th√¥ng tin c√°c thanh ki·∫øm
#         self.swords_db = []
#         self.embeddings = []
        
#     def add_sword_to_db(self, sword_id, image_path, name, description, features=""):
#         """Th√™m thanh ki·∫øm v√†o database"""
#         sword_info = {
#             "id": sword_id,
#             "image_path": image_path,
#             "name": name,
#             "description": description,
#             "features": features
#         }
        
#         # T·∫°o embedding cho s·∫£n ph·∫©m n√†y
#         embedding = self._create_sword_embedding(image_path, name, description, features)
        
#         self.swords_db.append(sword_info)
#         self.embeddings.append(embedding)
        
#     def _create_sword_embedding(self, image_path, name, description, features):
#         """T·∫°o embedding k·∫øt h·ª£p ·∫£nh + text cho 1 thanh ki·∫øm"""
#         # Load v√† process ·∫£nh
#         image = Image.open(image_path)
#         image_inputs = self.processor(images=image, return_tensors="pt")
        
#         # T·∫°o text m√¥ t·∫£ ƒë·∫ßy ƒë·ªß
#         full_text = f"{name}. {description}. {features}"
#         text_inputs = self.processor(text=[full_text], return_tensors="pt", padding=True)
        
#         # L·∫•y embeddings
#         with torch.no_grad():
#             image_embedding = self.model.get_image_features(**image_inputs)
#             text_embedding = self.model.get_text_features(**text_inputs)
        
#         # K·∫øt h·ª£p embedding (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh tr·ªçng s·ªë)
#         image_weight = 0.7  # ∆Øu ti√™n h√¨nh ·∫£nh h∆°n
#         text_weight = 0.3
        
#         combined_embedding = (image_weight * image_embedding + 
#                             text_weight * text_embedding)
        
#         # Normalize
#         combined_embedding = combined_embedding / combined_embedding.norm(dim=-1, keepdim=True)
        
#         return combined_embedding.numpy()
    
#     def search_similar_swords(self, query_image_path, query_text, top_k=5):
#         """T√¨m ki·∫øm thanh ki·∫øm t∆∞∆°ng t·ª± d·ª±a tr√™n ·∫£nh + text input"""
        
#         # T·∫°o embedding cho query
#         query_embedding = self._create_sword_embedding(
#             query_image_path, 
#             "", 
#             query_text, 
#             ""
#         )
        
#         # T√≠nh similarity v·ªõi t·∫•t c·∫£ s·∫£n ph·∫©m trong DB
#         if not self.embeddings:
#             return []
            
#         db_embeddings = np.vstack(self.embeddings)
#         similarities = cosine_similarity(query_embedding, db_embeddings)[0]
        
#         # L·∫•y top-k k·∫øt qu·∫£
#         top_indices = np.argsort(similarities)[::-1][:top_k]
        
#         results = []
#         for idx in top_indices:
#             sword = self.swords_db[idx]
#             similarity_score = similarities[idx]
            
#             results.append({
#                 "sword": sword,
#                 "similarity": float(similarity_score),
#                 "confidence": f"{similarity_score*100:.1f}%"
#             })
            
#         return results
    
#     def save_database(self, file_path):
#         """L∆∞u database ra file"""
#         data = {
#             "swords": self.swords_db,
#             "embeddings": [emb.tolist() for emb in self.embeddings]
#         }
#         with open(file_path, 'w', encoding='utf-8') as f:
#             json.dump(data, f, ensure_ascii=False, indent=2)
    
#     def load_database(self, file_path):
#         """Load database t·ª´ file"""
#         with open(file_path, 'r', encoding='utf-8') as f:
#             data = json.load(f)
        
#         self.swords_db = data["swords"]
#         self.embeddings = [np.array(emb) for emb in data["embeddings"]]

# # V√≠ d·ª• s·ª≠ d·ª•ng
# if __name__ == "__main__":
#     # Kh·ªüi t·∫°o h·ªá th·ªëng
#     sword_search = SwordSearchSystem()
    
#     # Th√™m c√°c thanh ki·∫øm v√†o database
#     sword_search.add_sword_to_db(
#         sword_id="katana_01",
#         image_path="katana_1.jpg",
#         name="Katana Samurai",
#         description="Thanh ki·∫øm Nh·∫≠t truy·ªÅn th·ªëng",
#         features="L∆∞·ª°i cong, c√°n d√†i, th√©p cao c·∫•p"
#     )
    
#     sword_search.add_sword_to_db(
#         sword_id="broadsword_01", 
#         image_path="broadsword_1.jpg",
#         name="Broad Sword",
#         description="Ki·∫øm r·ªông phong c√°ch ch√¢u √Çu",
#         features="L∆∞·ª°i r·ªông, hai l∆∞·ª°i c·∫Øt, c√°n ng·∫Øn"
#     )
    
#     # T√¨m ki·∫øm
#     results = sword_search.search_similar_swords(
#         query_image_path="user_sword_image.jpg",
#         query_text="T√¥i mu·ªën ƒë·ªïi sang thanh ki·∫øm Nh·∫≠t B·∫£n, ki·ªÉu cong, d√†i",
#         top_k=3
#     )
    
#     # Hi·ªÉn th·ªã k·∫øt qu·∫£
#     print("üó°Ô∏è G·ª£i √Ω thanh ki·∫øm ph√π h·ª£p:")
#     for i, result in enumerate(results, 1):
#         sword = result["sword"]
#         print(f"\n{i}. {sword['name']}")
#         print(f"   üìù {sword['description']}")
#         print(f"   ‚öîÔ∏è {sword['features']}")
#         print(f"   üéØ ƒê·ªô ph√π h·ª£p: {result['confidence']}")
#         print(f"   üîó ID: {sword['id']}")